# Select rows with the filter function
filter(pos_dat, totlngth > 95)
filter(pos_dat, sex == "m")
# Combine conditions
filter(pos_dat, totlngth > 95 & sex == "m")
#' We can also combine $\textcolor {MidnightBlue}{select}$ and $\textcolor {MidnightBlue}{filter}$:
select(filter(pos_dat, sex == "m"), totlngth, sex, skullw)
#' In this example, the output of $\textcolor {MidnightBlue}{filter}$ takes the position of
#' the *data* argument in the $\textcolor {MidnightBlue}{select}$ function. A particular strength of dplyr is the use of
#' [pipelines](https://en.wikipedia.org/wiki/Pipeline_(Unix)), defined in the R context as a sequence of functions, where the output from one
#' function feeds directly as input of the next function. This can also enhance readability. Consider for example the previous code
#' (combination of $\textcolor {MidnightBlue}{select}$ and $\textcolor {MidnightBlue}{filter}$) rewritten as pipe (pipe operator: %>%):
pos_dat %>%
filter(sex == "m") %>%
select(totlngth, sex, skullw)
#' dplyr also provides a useful function ($\textcolor {MidnightBlue}{arrange}$) to sort a dataframe according to selected variables:
pos_dat %>%
arrange(totlngth)
# now in descending order
pos_dat %>%
arrange(desc(totlngth))
#' Compare this to the sorting of dataframes in basic R, which is much less elegant:
ord_1 <- order(pos_dat[ ,"totlngth"])
pos_dat[ord_1, ]
#' We can also easily sort by multiple columns and afterwards select a few variables:
pos_dat %>%
arrange(age, desc(totlngth)) %>%
select(age, totlngth, belly)
#' Another useful function is $\textcolor {MidnightBlue}{rename}$:
pos_dat %>%
rename(total_length = totlngth)
# We inspect the original dataframe
head(pos_dat)
#' Why is the original name still in the dataframe? **What would you need to do, to keep the
#' changed name?**
#'
#' Finally, the mutate function allows to create new columns, for example, as
#' a function of existing columns:
pos_dat %>%
mutate(Sum_hdln_totlng = hdlngth + totlngth)
# Combined with subsetting to a few columns
pos_dat %>%
mutate(Sum_hdln_totlng = hdlngth + totlngth) %>%
select(sex, age, hdlngth, totlngth, Sum_hdln_totlng)
#' Still, you would need to assign this to a new object to store the changes.
#'
#' # Data exploration
#'
#' After we have learnt how to process data, we explore the data that will be analysed in the next session. Although graphical tools are most suitable
#' to obtain an overview on data, the $\textcolor {MidnightBlue}{summary}$ function quickly provides information on potential outliers,
#' missing values (*NA's*) and the range of data:
# Reset max.print options to 100 to avoid that information is omitted
options(max.print = 120)
summary(pos_dat)
#' For the categorical variables *Pop* and *sex* the function returns the number of cases per level. For numerical variables, the minimum, maximum,
#' quartiles, median and mean are returned. In the following we use the cleveland plot and boxplot to check for potential errors and outliers.
#' Let us first look at a cleveland plot:
dotchart(pos_dat$totlngth)
# Provides an overview, but plot would benefit from polishing.
# Increase font size of labels and symbols
par(cex = 1.4)
# Check ?par for explanation and overview of other arguments
dotchart(pos_dat$totlngth,cex.lab = 1.3,
xlab = "Total length [cm]", main = "Data overview")
#' No outlier is visible. This is how an outlier would look like:
#+ echo = FALSE
totlng_outl <- c(pos_dat$totlngth, 830)
dotchart(totlng_outl,cex.lab = 1.3,
xlab = "Total length [cm]", main = "Data overview")
#' The observation at 830 ist an extreme outlier. If you spot such an extreme difference to the remainder
#' of the data, you should scrutinise the raw data, because an order of magnitude difference points
#' to an error with a decimal point during data entry. Another useful tool that can be used for
#' different purposes including checking for outliers is the boxplot (for brief explanation and different types
#' [visit the R graph gallery](https://www.r-graph-gallery.com/boxplot/)).
boxplot(pos_dat$totlngth, las = 1, cex.lab = 1.3,
ylab = "Total length [cm]", main = "Data overview")
# For the same variable with an added outlier
boxplot(totlng_outl, las = 1, cex.lab = 1.3,
ylab = "Total length [cm]", main = "Data overview")
#' You can save a figure from the graphics device using the graphical user interface (*Export* in R Studio). Direct export of
#' a figure without plotting in R Studio can be done using specific functions such as $\textcolor {MidnightBlue}{jpeg}$,
#' $\textcolor {MidnightBlue}{png}$ or $\textcolor {MidnightBlue}{pdf}$. For details see $\textcolor {MidnightBlue}{?jpeg}$ and
#' $\textcolor {MidnightBlue}{?pdf}$
#+ eval = FALSE
# example for directly exporting the boxplot to a file
jpeg("Boxplot.jpeg", quality = 100)
par(cex = 1.4)
boxplot(pos_dat$totlngth, las = 1, cex.lab = 1.3,
ylab = "Total length [cm]", main = "Data overview")
dev.off()
# Switches off the device (here: saves content to file in working directory)
#' Although the boxplot is widely used and you should be familiar with its interpretation, interesting alternatives such as the beanplot
#' have been introduced [@KampstraBeanplotBoxplotAlternative2008]. The related paper is [available via open access](http://www.jstatsoft.org/v28/c01/).
#' Refer to the paper and the lecture for explanation of the plot. We first load and attach the package:
library(beanplot)
#' If you do not have the package installed, you need to install the package via:
# install.packages("beanplot") # (remove comment in this case)
#' Now we create a beanplot for the total lenght of possums
beanplot(pos_dat$totlngth)
# provides single observations (lines), mean (thick line) and
# displays the estimated probability density distribution (black polygon)
#' Again, a few additional arguments improve the quality of the figure. It is quite handy
#' that these arguments are the same as for the boxplot or dotchart:
beanplot(pos_dat$totlngth, las = 1, cex.lab = 1.3,
ylab = "Total length [cm]", main = "Data overview")
summary(pos_dat)
plot(totlngth ~ Pop, data = pos_dat)
#' Both the boxplot and beanplot are practical tools to compare the distribution among variables or groups. Several statistical tests
#' for between group differences (e.g. *t*-test or analysis of variance) require that the variance is homogeneous across groups.
#' This homogeneity of variance translates to a similar spread of the data around the mean. Examplarily, we inspect the distribution
#' of possums from Victoria and from other states with a conditional boxplot:
boxplot(totlngth ~ Pop, data = pos_dat)
#' Both the boxplot and beanplot are practical tools to compare the distribution among variables or groups. Several statistical tests
#' for between group differences (e.g. *t*-test or analysis of variance) require that the variance is homogeneous across groups.
#' This homogeneity of variance translates to a similar spread of the data around the mean. Examplarily, we inspect the distribution
#' of possums from Victoria and from other states with a conditional boxplot:
plot(totlngth ~ Pop, data = pos_dat)
#' Both the boxplot and beanplot are practical tools to compare the distribution among variables or groups. Several statistical tests
#' for between group differences (e.g. *t*-test or analysis of variance) require that the variance is homogeneous across groups.
#' This homogeneity of variance translates to a similar spread of the data around the mean. Examplarily, we inspect the distribution
#' of possums from Victoria and from other states with a conditional boxplot:
boxplot(totlngth ~ Pop, data = pos_dat)
boxplot(totlngth ~ Pop, data = pos_dat, las = 1, cex.lab = 1.3,
ylab = "Total length [cm]", xlab = "Possum population")
pos_dat %>%
group_by(Pop) %>%
select(totlngth)
pos_dat %>%
group_by(Pop) %>%
select(totlngth) %>%
summarise(med = median)
pos_dat %>%
group_by(Pop)
pos_dat %>%
group_by(Pop) %>%
select(totlngth, Pop)
pos_dat %>%
group_by(Pop) %>%
select(totlngth, Pop) %>%
summarise(med = median(totlngth))
tapply
?tapply
#' The *tilde* sign ~ is used in R to formulate statistical models, where the response variable(s) are on the left hand side
#' and the explanatory variables/predictors on the right hand side. Here, it automatically plots the responses per factor level
#' of the variable *Pop*.
#'
#' To ease visual comparison of the spread around the median, we put both variables on the same median. This can be done with the base
#' R function $\textcolor {MidnightBlue}{tapply}$ that applies a function to each group of data defined by the levels of a factor.
med <- tapply(pos_dat$totlngth, pos_dat$Pop, median)
# first argument: data, second argument: factor, third argument: function
# to be applied to each group defined by the factor
med
pos_dat %>%
group_by(Pop) %>%
select(totlngth, Pop) %>%
summarise(med = median(totlngth))
med_2 <- pos_dat %>%
group_by(Pop) %>%
select(totlngth, Pop) %>%
summarise(med = median(totlngth))
med[pos_dat$Pop]
med
pos_dat$totlngth
#' Note that a different type of object is produced using dplyr: a [tibble](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html).
#'
#' Anyway, we proceed with the basic R functions and now substract the respective median from each observation of the groups.
w <- pos_dat$totlngth - med[pos_dat$Pop]
w
#' **Check what med[pos_dat$Pop] does with the object med.**
#' The resulting vector *w* gives the distance of each observation to the median of its group. Mathematically,
#' this is equivalent to setting the median of both data sets to 0. We now plot again:
plot(w ~ Pop, data = pos_dat)
boxplot(w ~ Pop, data = pos_dat, las = 1, cex.lab = 1.3,
ylab = "Distance to median [cm]", xlab = "Possum population")
beanplot(w ~ Pop, data = pos_dat, las = 1, cex.lab = 1.3,
ylab = "Distance to median [cm]", xlab = "Possum population")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
# we need to check for each sample (i.e. from Victoria and other states)
# quantile-quantile plot
qqnorm(pos_dat$totlngth[pos_dat$Pop =="other" ], datax = TRUE)
# data fit the line relatively well, though some deviation is visible
qqline(pos_dat$totlngth[pos_dat$Pop =="other" ], datax = TRUE)
#' the beanplot relies on the mean. **Try to produce the same plot with the mean substracted from each observation!** *Hint:
#' the function to calculate the mean is mean().*
#'
#' Another assumption of several data analysis tools is that the data is normally distributed. This can be checked using
#' the so-called *QQ-plot*, which plots theoretical quantiles from a normal distribution against the sample quantiles
#' (the definition and interpretation of Quantiles is explained in the lecture). Obviously, if the data originate from a
#' normal distribution, the sample quantiles should approximately follow a 1:1 relationship. For statistical tests focusing on
#' between-group differences, the assumption would need to be checked for each group. Here, we ignore any potential grouping
#' of the data and exemplify the QQ-plot for the variable total length:
# quantile-quantile plot
qqnorm(pos_dat$totlngth, datax = TRUE)
qqnorm(pos_dat$totlngth)
?qqline
#' the beanplot relies on the mean. **Try to produce the same plot with the mean substracted from each observation!** *Hint:
#' the function to calculate the mean is mean().*
#'
#' Another assumption of several data analysis tools is that the data is normally distributed. This can be checked using
#' the so-called *QQ-plot*, which plots theoretical quantiles from a normal distribution against the sample quantiles
#' (the definition and interpretation of Quantiles is explained in the lecture). Obviously, if the data originate from a
#' normal distribution, the sample quantiles should approximately follow a 1:1 relationship. For statistical tests focusing on
#' between-group differences, the assumption would need to be checked for each group. Here, we ignore any potential grouping
#' of the data and exemplify the QQ-plot for the variable total length:
# Quantile-Quantile plot
qqnorm(pos_dat$totlngth, datax = TRUE)
# We add a line that goes through the first and third quartiles,
# which helps to spot deviations.
qqline(pos_dat$totlngth, datax = TRUE)
library(DAAG)
qreference(pos_dat$totlngth, nrep = 8)
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
?qreference
qreference(pos_dat$totlngth, nrep = 8, xlab = "Sample ")
qreference(pos_dat$totlngth, nrep = 8, xlab = "Theoretical Quantiles",
ylab = "Sample Quantiles")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
?rbinom
x
rchisq(15, 3)
y <- rchisq(15, df = 2)
qreference(y, nrep = 8)
y <- rchisq(15, df = 5)
qreference(y, nrep = 8)
y <- rchisq(15, df = 10)
qreference(y, nrep = 8)
y <- rchisq(15, df = 6)
qreference(y, nrep = 8)
y <- runif(15)
qreference(y, nrep = 8)
y <- runif(15, min = 0, max = 2)
qreference(y, nrep = 8)
y <- runif(30, min = 0, max = 2)
qreference(y, nrep = 8)
y <- runif(50, min = 0, max = 2)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 2)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 1)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 10)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 20)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 20)
qreference(y, nrep = 8)
y <- runif(75, min = 0, max = 20)
qreference(y, nrep = 8)
set.seed(2018)
y <- runif(75, min = 0, max = 20)
qreference(y, nrep = 8)
qqnorm(y)
# We add a line that goes through the first and third quartiles,
# which helps to spot deviations.
qqline(y)
set.seed(2018)
y <- runif(50, min = 0, max = 20)
qreference(y, nrep = 8)
qqnorm(y)
# We add a line that goes through the first and third quartiles,
# which helps to spot deviations.
qqline(y)
# nrep controls the number of reference plots
#' The reference plots give an idea how data randomly sampled data from a normal distribution can deviate from the theoretical
#' normal distribution. Clearly, the data (blue) does not look conspicuous when compared to the reference plots (purple).
#'
#' A similar approach is to plot the QQ plot for the data and reference QQ plots without indication which QQ plot relates to the data.
#' Unless the data deviate strongly from a normal distribution, the QQ plot related to the data is presumably indistinguishable from
#' reference plots. The code for this approach is provided in a [blog](https://biologyforfun.wordpress.com/2014/04/16/checking-glm-model-assumptions-in-r/).
#'
#' How would a strong deviation look? We discuss two examples. First, we draw samples from a binomial distribution:
set.seed(2018)
x <- rbinom(n = 15, size = 5, p = 0.6)
qreference(x, nrep = 8)
qqnorm(x)
# We add a line that goes through the first and third quartiles,
# which helps to spot deviations.
qqline(x)
#
qreference(x, nrep = 8)
?set.seed
#' Again, we use the QQ plot to evaluate normal distribution:
qqnorm(y)
qqline(y)
set.seed(2018)
y <- runif(50, min = 0, max = 20)
#' Again, we use the QQ plot to evaluate normal distribution:
qqnorm(y)
qqline(y)
#' A strong deviation is visible, particularly for the lower and upper Quantiles. This impression is confirmed when
#' comparing the QQ plot for the data to QQ reference plots.
qreference(y, nrep = 8)
shapiro.test(x)
#' Another useful tool is the histogram. It can be used to check normality of the data, symmetry and whether the data is
#' bi- or multi-modal. Typically, the histogram displays the frequency with which values of the data fall into typically
#' same-sized intervals.
hist(pos_dat$totlngth)
#' Another useful tool is the histogram. It can be used to check normality of the data, symmetry and whether the data is
#' bi- or multi-modal. Typically, the histogram displays the frequency with which values of the data fall into typically
#' same-sized intervals. For example, we plot the data from non-Victorian possum populations
hist(pos_dat$totlngth[pos_dat$Pop =="other" ])
#' Another useful tool is the histogram. It can be used to check normality of the data, symmetry and whether the data is
#' bi- or multi-modal. Typically, the histogram displays the frequency with which values of the data fall into typically
#' same-sized intervals. For example, we plot the data from non-Victorian possum populations
hist(pos_dat$totlngth[pos_dat$Pop =="Vic" ])
# shows frequency
hist(pos_dat$totlngth[pos_dat$Pop =="Vic" ], probability = TRUE)
# add density lines
dens <- density(pos_dat$totlngth[pos_dat$Pop =="Vic" ])
# estimates the density using a given smoother
lines(dens)
?density
?hist
range(dens$x)
range(dens$y)
xlim <- range(pos_dat$totlngth[pos_dat$Pop =="Vic" ])
xlim
xlim*1.2
range(dens$y)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5, probability = TRUE,
xlim = c(70, 105), ylim = c(0, 0.15),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="Vic" ], breaks = 72.5 + (0:5) * 5, probability = TRUE,
xlim = c(70, 105), ylim = c(0, 0.15),
xlab = "Total length (cm)", main = "")
lines(dens)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5, probability = TRUE,
xlim = c(70, 105), ylim = c(0, 0.15),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 0.15),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 20),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 30),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26),
xlab = "Total length (cm)", main = "")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26),
xlab = "Total length (cm)", main = "", las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 75 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26),
xlab = "Total length (cm)", main = "", las = 1)
par(mfrow = c(2,2))
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 5, main = "5 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 10, main = "10 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20, main = "20 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 50, main = "50 breaks")
par(mfrow = c(2,2), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 5, main = "5 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 10, main = "10 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20, main = "20 breaks")
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 50, main = "50 breaks")
#' Adding density lines to histograms aids in reducing the effect of the number
#' of breaks and the position of the break points. The density lines are derived
#' from the empirical density distribution of the data.
# Derive density line
dens <- density(pos_dat$totlngth[pos_dat$Pop =="other" ])
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26),
xlab = "Total length (cm)", main = "", las = 1)
lines(dens)
par(mfrow = c(1,2), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26),
xlab = "Total length (cm)", main = "", las = 1)
lines(dens)
par(mfrow = c(1,2), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 26), probability = TRUE,
xlab = "Total length (cm)", main = "", las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 0.15), probability = TRUE,
xlab = "Total length (cm)", main = "", las = 1)
par(mfrow = c(1,2), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 72.5 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 0.15), probability = TRUE,
xlab = "Total length (cm)", main = "", las = 1)
lines(dens)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 75 + (0:5) * 5,
xlim = c(70, 105), ylim = c(0, 0.15), probability = TRUE,
xlab = "Total length (cm)", main = "")
lines(dens)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20,
xlim = c(70, 105), ylim = c(0, 0.15), probability = TRUE,
xlab = "Total length (cm)", main = "20 breaks")
lines(dens)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20,
xlim = c(70, 105), ylim = c(0, 0.2), probability = TRUE,
xlab = "Total length (cm)", main = "20 breaks")
par(mfrow = c(1,1), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20,
xlim = c(70, 105), ylim = c(0, 0.2), probability = TRUE,
xlab = "Total length (cm)", main = "20 breaks")
lines(dens)
#' The empirical cumulative distribution function can be calculated and plotted with:
ecdf_tot <- ecdf(pos_dat$totlngth[pos_dat$Pop =="other" ])
plot(ecdf_tot)
par(mfrow = c(1,1), las = 1)
hist(pos_dat$totlngth[pos_dat$Pop =="other" ], breaks = 20,
xlim = c(70, 105), ylim = c(0, 0.2), probability = TRUE,
xlab = "Total length (cm)", main = "20 breaks")
lines(dens)
#' To evaluate normality of a data in a histogram can be done by overlaying a density line from
#' a theoretical normal probability distribution. To do this, we generate a normal distribution
#' with the parameters (i.e. mean and variance) taken from the sample data.
# calculate mean
mean_samp <- mean(pos_dat$totlngth[pos_dat$Pop =="other" ])
?dnrom
?dnorm
mean_samp <- mean(pos_dat$totlngth[pos_dat$Pop =="other" ])
# calculate standard deviation
sd_samp <- sd(pos_dat$totlngth[pos_dat$Pop =="other" ])
# derive densities for normal distribution
dens_norm <- dnorm(pos_dat$totlngth[pos_dat$Pop =="other" ], mean = m, sd = std)
# add to plot
curve(dens_norm, col="darkblue", lwd=2, add=TRUE, yaxt="n")
# derive densities for normal distribution
dens_norm <- dnorm(pos_dat$totlngth[pos_dat$Pop =="other" ], mean = mean_samp, sd = sd_samp)
# add to plot
curve(dens_norm, col="darkblue", lwd=2, add=TRUE, yaxt="n")
# add to plot
curve(dnorm(pos_dat$totlngth[pos_dat$Pop =="other" ], mean = mean_samp, sd = sd_samp), col="darkblue", lwd=2, add=TRUE, yaxt="n")
# add to plot
curve(dnorm(x, mean = mean_samp, sd = sd_samp), col="darkblue", lwd=2, add=TRUE, yaxt="n")
Vic_pos <- pos_dat %>%
filter(Pop == "Vic") %>%
select(totlngth)
hist(Vic_pos)
Vic_pos
str(Vic_pos)
hist(Vic_pos$totlngth)
hist(c(Vic_pos))
as.vector(Vic_pos)
# convert to vector, otherwise histogram function
# throws an error
Vic_pos2 <- as.vector(Vic_pos)
hist(Vic_pos2)
Vic_pos2
is.numeric(Vic_pos2)
str(Vic_pos2)
# convert to vector, otherwise histogram function
# throws an error
Vic_pos2 <- as.vector(t(Vic_pos))
Vic_pos2
# create histogram
hist(Vic_pos2)
# Intervals have a width of 5
#' The histogram shows that more than 15 possums had a lenght between 85 and 90 cm, whereas 11 and 12 possums had a lenght
#' between 80 and 85 and between 90 and 95, respectively. Instead of absolute frequencies, the histogram can also be used
#' to display relativy frequencies, i.e. the probability densities:
hist(Vic_pos2, probability = TRUE)
nVic_pos <- pos_dat %>%
filter(Pop == "other") %>%
select(totlngth)
# convert to vector
nVic_pos2 <- as.vector(t(nVic_pos))
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
?curve
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
devtools::install_github("lbusett/insert_table"
)
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
#' If loaded and attached, we can subsequently load the possum data, which we have imported from a file above,
#' quite conveniently (e.g. without the need to specify separator or decimal point) from the package:
data(possum)
#' The file was taken from the R package [DAAG](https://cran.r-project.org/web/packages/DAAG/index.html) and contains information on
#' [possums](https://en.wikipedia.org/wiki/Phalangeridae#/media/File:Brushtail_possum.jpg) that were published in @LindenmayerMorphologicalVariationPopulations1995. To access an R package, we have
#' to load and attach a package with the function $\textcolor {MidnightBlue}{library}$:
#+ eval=FALSE
library(DAAG)
#' If loaded and attached, we can subsequently load the possum data, which we have imported from a file above,
#' quite conveniently (e.g. without the need to specify separator or decimal point) from the package:
data(possum)
#' the character for the decimal point is ",", which often leads to trouble (unless you do not exchange
#' files with others). In academic contexts, I generally recommend to set all software products such as spreadsheet programs
#' (e.g. Microsoft Excel, LibreOffice Calc) [to locale "English (Great Britain)"](https://help.libreoffice.org/Common/Languages#Locale_setting)
#' or another locale related to an english-speaking country.
#' * row.names: specify row names, a variable that provides row names (our data set actually contains a variable
#' *row.names*, but we ignore that) or import without row names (= NULL)
#'
#' Call $\textcolor {MidnightBlue}{?read.table}$ for further details and options.
#' Misspecification of import arguments is one of the most frequent errors of beginners.
#' We run the import function again, now with the arguments properly specified.
pos_dat <- read.table(url(link), dec = ".", sep = ";", header = TRUE, row.names = NULL)
rm(list = ls())
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
pos_dat %>% filter(pop = "other") %>% select(sex) %>% count
pos_dat %>% filter(pop == "other") %>% select(sex) %>% count
pos_dat %>% filter(Pop == "other") %>% select(sex) %>% count
pos_dat %>% filter(Pop == "other") %>% select(sex) %>% group_by(sex) %>% count
pos_dat %>% filter(Pop == "Vic") %>% select(sex) %>% group_by(sex) %>% count
pos_dat %>%
select(sex, Pop) %>%
group_by(Pop, sex) %>%
count
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
rmarkdown::render("/Users/ralfs/Gitprojects/Teaching/Data_analysis/Code/Session_1.R")
